{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINANCE COMPLAINT PROJECT\n",
    "\n",
    "### Feature Engineering & Model Training\n",
    "\n",
    "##### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in d:\\bala\\project_inprogress\\finance\\venv\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: numpy in d:\\bala\\project_inprogress\\finance\\venv\\lib\\site-packages (from hyperopt) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\bala\\project_inprogress\\finance\\venv\\lib\\site-packages (from hyperopt) (1.14.1)\n",
      "Requirement already satisfied: six in c:\\users\\balaj\\appdata\\roaming\\python\\python311\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in d:\\bala\\project_inprogress\\finance\\venv\\lib\\site-packages (from hyperopt) (3.3)\n",
      "Requirement already satisfied: future in d:\\bala\\project_inprogress\\finance\\venv\\lib\\site-packages (from hyperopt) (1.0.0)\n",
      "Requirement already satisfied: tqdm in d:\\bala\\project_inprogress\\finance\\venv\\lib\\site-packages (from hyperopt) (4.66.5)\n",
      "Requirement already satisfied: cloudpickle in d:\\bala\\project_inprogress\\finance\\venv\\lib\\site-packages (from hyperopt) (3.0.0)\n",
      "Requirement already satisfied: py4j in d:\\bala\\project_inprogress\\finance\\venv\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\balaj\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->hyperopt) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#!pip install plotly\n",
    "#!pip install nltk\n",
    "#!pip install scikit-learn\n",
    "#!pip install xgboost\n",
    "#!pip install catboost\n",
    "#!pip install category_encoders\n",
    "#!pip install imbalanced-learn\n",
    "!pip install hyperopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# For Text Processing\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, FreqDist\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "#For Classification Model Selection\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "# For data-preprocessing \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "#For Hyperparameter Tuning\n",
    "from hyperopt import tpe,hp,Trials,space_eval\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll import scope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Bala\\\\Project_Inprogress\\\\Finance\\\\notebook'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\Bala\\Project_Inprogress\\Finance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>company_public_response</th>\n",
       "      <th>company_response</th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>consumer_consent_provided</th>\n",
       "      <th>consumer_disputed</th>\n",
       "      <th>date_received</th>\n",
       "      <th>date_sent_to_company</th>\n",
       "      <th>issue</th>\n",
       "      <th>product</th>\n",
       "      <th>state</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>submitted_via</th>\n",
       "      <th>tags</th>\n",
       "      <th>timely</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portfolio Recovery Associates</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ID000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>Billing disputes</td>\n",
       "      <td>Retail store card</td>\n",
       "      <td>TX</td>\n",
       "      <td>None</td>\n",
       "      <td>Store credit card</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fifth Third Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>Company believes it acted appropriately</td>\n",
       "      <td>ID000001</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>Payment processing issues</td>\n",
       "      <td>Auto loan</td>\n",
       "      <td>PA</td>\n",
       "      <td>Improper reporting</td>\n",
       "      <td>None</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Unresolved complaint</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bank of America</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ID000002</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>Unauthorized charges</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>CO</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Web</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chase Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ID000003</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Payment processing issues</td>\n",
       "      <td>Personal loan</td>\n",
       "      <td>WA</td>\n",
       "      <td>None</td>\n",
       "      <td>Other bank product/service</td>\n",
       "      <td>Web</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Express Company</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ID000004</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>2022-02-26</td>\n",
       "      <td>Service not received</td>\n",
       "      <td>Auto loan</td>\n",
       "      <td>TX</td>\n",
       "      <td>Application denied</td>\n",
       "      <td>General-purpose credit card</td>\n",
       "      <td>Web</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         company company_public_response  \\\n",
       "0  Portfolio Recovery Associates                    None   \n",
       "1               Fifth Third Bank                    None   \n",
       "2                Bank of America                    None   \n",
       "3                     Chase Bank                    None   \n",
       "4       American Express Company                    None   \n",
       "\n",
       "                          company_response complaint_id  \\\n",
       "0                                     None     ID000000   \n",
       "1  Company believes it acted appropriately     ID000001   \n",
       "2                                     None     ID000002   \n",
       "3                                     None     ID000003   \n",
       "4                                     None     ID000004   \n",
       "\n",
       "  complaint_what_happened consumer_consent_provided consumer_disputed  \\\n",
       "0                     Yes      Consent not provided               Yes   \n",
       "1                     Yes      Consent not provided                No   \n",
       "2                     Yes      Consent not provided                No   \n",
       "3                     Yes      Consent not provided                No   \n",
       "4                     Yes      Consent not provided               Yes   \n",
       "\n",
       "  date_received date_sent_to_company                      issue  \\\n",
       "0    2023-08-03           2023-01-26           Billing disputes   \n",
       "1    2024-01-09           2024-06-13  Payment processing issues   \n",
       "2    2023-06-14           2022-05-13       Unauthorized charges   \n",
       "3    2022-02-13           2024-08-31  Payment processing issues   \n",
       "4    2023-10-03           2022-02-26       Service not received   \n",
       "\n",
       "             product state           sub_issue                  sub_product  \\\n",
       "0  Retail store card    TX                None            Store credit card   \n",
       "1          Auto loan    PA  Improper reporting                         None   \n",
       "2          Insurance    CO                None                         None   \n",
       "3      Personal loan    WA                None   Other bank product/service   \n",
       "4          Auto loan    TX  Application denied  General-purpose credit card   \n",
       "\n",
       "  submitted_via                  tags timely zip_code  \n",
       "0   Postal mail                  None    Yes     None  \n",
       "1         Phone  Unresolved complaint    Yes     None  \n",
       "2           Web                  None    Yes     None  \n",
       "3           Web                  None    Yes    12468  \n",
       "4           Web                  None     No     None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"input.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As per Final EDA report we can remove some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub_issue</th>\n",
       "      <td>78.0828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_product</th>\n",
       "      <td>78.0524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>77.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_response</th>\n",
       "      <td>77.1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_public_response</th>\n",
       "      <td>77.1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <td>75.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submitted_via</th>\n",
       "      <td>4.9192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0\n",
       "sub_issue                78.0828\n",
       "sub_product              78.0524\n",
       "tags                     77.3056\n",
       "company_response         77.1952\n",
       "company_public_response  77.1548\n",
       "zip_code                 75.0020\n",
       "submitted_via             4.9192\n",
       "product                   0.0000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df.isnull().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0,ascending=False)\n",
    "missing[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['tags', 'complaint_what_happened', 'company_public_response', 'sub_issue', 'sub_product', 'zip_code', 'complaint_id', 'company']\n",
    "df.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>company_response</th>\n",
       "      <td>77.1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submitted_via</th>\n",
       "      <td>4.9192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumer_consent_provided</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumer_disputed</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_received</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_sent_to_company</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0\n",
       "company_response           77.1952\n",
       "submitted_via               4.9192\n",
       "consumer_consent_provided   0.0000\n",
       "consumer_disputed           0.0000\n",
       "date_received               0.0000\n",
       "date_sent_to_company        0.0000\n",
       "issue                       0.0000\n",
       "product                     0.0000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df.isnull().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0,ascending=False)\n",
    "missing[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>date_sent_to_company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>2023-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>2024-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-14</td>\n",
       "      <td>2022-05-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_received date_sent_to_company\n",
       "0    2023-08-03           2023-01-26\n",
       "1    2024-01-09           2024-06-13\n",
       "2    2023-06-14           2022-05-13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['date_received','date_sent_to_company']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_to_forward_complaint']=pd.to_datetime(df['date_sent_to_company'])-pd.to_datetime(df['date_received'])\n",
    "\n",
    "df['days_to_forward_complaint'] = df['days_to_forward_complaint'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['date_received','date_sent_to_company'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Model to reduce computation time we can use sample of the data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>company_response</th>\n",
       "      <th>consumer_consent_provided</th>\n",
       "      <th>consumer_disputed</th>\n",
       "      <th>issue</th>\n",
       "      <th>product</th>\n",
       "      <th>state</th>\n",
       "      <th>submitted_via</th>\n",
       "      <th>timely</th>\n",
       "      <th>days_to_forward_complaint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92142</td>\n",
       "      <td>Investigation ongoing</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Service not received</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>OR</td>\n",
       "      <td>Web</td>\n",
       "      <td>Yes</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31566</td>\n",
       "      <td>Closed with monetary relief</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NC</td>\n",
       "      <td>Web</td>\n",
       "      <td>Yes</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239128</td>\n",
       "      <td>None</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Identity theft issues</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>VA</td>\n",
       "      <td>Web</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97276</td>\n",
       "      <td>None</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Loan application denied</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Web</td>\n",
       "      <td>No</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100792</td>\n",
       "      <td>None</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Unauthorized charges</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>IN</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>No</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index             company_response consumer_consent_provided  \\\n",
       "0   92142        Investigation ongoing      Consent not provided   \n",
       "1   31566  Closed with monetary relief      Consent not provided   \n",
       "2  239128                         None          Consent provided   \n",
       "3   97276                         None      Consent not provided   \n",
       "4  100792                         None      Consent not provided   \n",
       "\n",
       "  consumer_disputed                                              issue  \\\n",
       "0                No                               Service not received   \n",
       "1                No  Problem with a credit reporting company's inve...   \n",
       "2                No                              Identity theft issues   \n",
       "3                No                            Loan application denied   \n",
       "4                No                               Unauthorized charges   \n",
       "\n",
       "            product state submitted_via timely  days_to_forward_complaint  \n",
       "0          Mortgage    OR           Web    Yes                        560  \n",
       "1  Credit reporting    NC           Web    Yes                        682  \n",
       "2      Student loan    VA           Web    Yes                       -611  \n",
       "3  Credit reporting    AZ           Web     No                        512  \n",
       "4  Credit reporting    IN   Postal mail     No                        804  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample data\n",
    "\n",
    "df1 = df.groupby(\"consumer_disputed\").sample(n=50000)\n",
    "df1.reset_index(inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Vectorization\n",
    "1. TFIDF -> term frequency - inverse document frequency\n",
    "2. CountVectorizer\n",
    "3. NLTK/Scipy Library\n",
    "4. Pretrained Glove\n",
    " \n",
    " -> here we can use TFIDF to process\n",
    "\n",
    "### Steps for text preprocessing\n",
    "1. Remove Punctuation\n",
    "2. Remove Stop Words\n",
    "3. Lower Case\n",
    "4. Tokenization\n",
    "5. Stemming/Lemmatization\n",
    "\n",
    "For this \"issue\" column has text which needs to be processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of Stop words which has to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english') + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to tokenize and lemmatize text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize data and remove stopwords\n",
    "\n",
    "def process_text(issue):\n",
    "\n",
    "    #create tokens\n",
    "    tokens = nltk.word_tokenize(issue)\n",
    "\n",
    "    #remove common stopwords\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "\n",
    "    #remove stopwords including few punctuation\n",
    "    stopwords_removed = [word for word in stopwords_removed if word.isalpha() ]\n",
    "    \n",
    "    return stopwords_removed\n",
    "\n",
    "# Concat the strings\n",
    "def concat_the_strings(words_list):\n",
    "    concat_words = \"\"\n",
    "    for word in words_list:\n",
    "        concat_words+= word + ' '\n",
    "\n",
    "    return concat_words\n",
    "\n",
    "# function to lemmatize words and merge eeach complaint into a single space-separated string\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_concat(words_list):\n",
    "    #remove any NaN's\n",
    "    list_of_words = [i for i in words_list if i is not np.nan]\n",
    "\n",
    "    # lemmatize each word\n",
    "    lemmatized_list = []\n",
    "    for idx, word in enumerate(words_list):\n",
    "        lemmatized_list.append(lemm.lemmatize(word))\n",
    "\n",
    "    # make the list into a single string with the words separated by ' '\n",
    "    final_string = concat_the_strings(lemmatized_list)\n",
    "\n",
    "    return final_string    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data with Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\balaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK stopwords pre requisite import\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Row Number 0\n",
      "Processed Row Number 5000\n",
      "Processed Row Number 10000\n",
      "Processed Row Number 15000\n",
      "Processed Row Number 20000\n",
      "Processed Row Number 25000\n",
      "Processed Row Number 30000\n",
      "Processed Row Number 35000\n",
      "Processed Row Number 40000\n",
      "Processed Row Number 45000\n",
      "Processed Row Number 50000\n",
      "Processed Row Number 55000\n",
      "Processed Row Number 60000\n",
      "Processed Row Number 65000\n",
      "Processed Row Number 70000\n",
      "Processed Row Number 75000\n",
      "Processed Row Number 80000\n",
      "Processed Row Number 85000\n",
      "Processed Row Number 90000\n",
      "Processed Row Number 95000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df1)):\n",
    "    text = process_text(df1['issue'].loc[i])\n",
    "    final_texts = lemmatizer_concat(text)\n",
    "    df1['issue'].loc[i] = final_texts\n",
    "    if i % 5000 == 0:\n",
    "        print(f'Processed Row Number {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the processed texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidv = TfidfVectorizer(max_features=None, strip_accents='unicode',analyzer='word',ngram_range=(1,2))\n",
    "\n",
    "#Get data after vectorizing issue column\n",
    "df_vect = tfidv.fit_transform(df1['issue'])\n",
    "\n",
    "feature_names = tfidv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Concat old data with vectorized data from issue text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df1, pd.DataFrame(df_vect.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After processing issue column as vectors, Now issue column can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(['issue', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X = df1.drop(['consumer_disputed'], axis=1)\n",
    "y = df1['consumer_disputed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 62)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of Train data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize features for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for binary encoder\n",
    "binary_features = ['product', 'state', 'submitted_via', 'company_response'] \n",
    "# for onehot encoder\n",
    "onhot_features = ['consumer_consent_provided', 'timely', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_response</th>\n",
       "      <th>consumer_consent_provided</th>\n",
       "      <th>consumer_disputed</th>\n",
       "      <th>product</th>\n",
       "      <th>state</th>\n",
       "      <th>submitted_via</th>\n",
       "      <th>timely</th>\n",
       "      <th>days_to_forward_complaint</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investigation ongoing</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>OR</td>\n",
       "      <td>Web</td>\n",
       "      <td>Yes</td>\n",
       "      <td>560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Closed with monetary relief</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NC</td>\n",
       "      <td>Web</td>\n",
       "      <td>Yes</td>\n",
       "      <td>682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350825</td>\n",
       "      <td>0.350825</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>VA</td>\n",
       "      <td>Web</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.472621</td>\n",
       "      <td>0.472621</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Web</td>\n",
       "      <td>No</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>IN</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>No</td>\n",
       "      <td>804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              company_response consumer_consent_provided consumer_disputed  \\\n",
       "0        Investigation ongoing      Consent not provided                No   \n",
       "1  Closed with monetary relief      Consent not provided                No   \n",
       "2                         None          Consent provided                No   \n",
       "3                         None      Consent not provided                No   \n",
       "4                         None      Consent not provided                No   \n",
       "\n",
       "            product state submitted_via timely  days_to_forward_complaint  \\\n",
       "0          Mortgage    OR           Web    Yes                        560   \n",
       "1  Credit reporting    NC           Web    Yes                        682   \n",
       "2      Student loan    VA           Web    Yes                       -611   \n",
       "3  Credit reporting    AZ           Web     No                        512   \n",
       "4  Credit reporting    IN   Postal mail     No                        804   \n",
       "\n",
       "     0    1  ...       45   46        47        48       49       50  \\\n",
       "0  0.0  0.0  ...  0.57735  0.0  0.000000  0.000000  0.57735  0.57735   \n",
       "1  0.0  0.0  ...  0.00000  0.0  0.350825  0.350825  0.00000  0.00000   \n",
       "2  0.0  0.0  ...  0.00000  0.0  0.000000  0.000000  0.00000  0.00000   \n",
       "3  0.0  0.0  ...  0.00000  0.0  0.000000  0.000000  0.00000  0.00000   \n",
       "4  0.0  0.0  ...  0.00000  0.0  0.000000  0.000000  0.00000  0.00000   \n",
       "\n",
       "         51        52       53       54  \n",
       "0  0.000000  0.000000  0.00000  0.00000  \n",
       "1  0.000000  0.000000  0.00000  0.00000  \n",
       "2  0.472621  0.472621  0.00000  0.00000  \n",
       "3  0.000000  0.000000  0.00000  0.00000  \n",
       "4  0.000000  0.000000  0.57735  0.57735  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create columntrasnformer for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder_pipeline = Pipeline(steps=[\n",
    "    ('SimpleImputer', SimpleImputer (strategy = 'most_frequent')), \n",
    "    ('OneHot_encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "binary_encoder_pipeline = Pipeline(steps=[\n",
    "    ('SimpleImputer', SimpleImputer (strategy = 'most_frequent')), \n",
    "    ('BinaryEncoder', BinaryEncoder())\n",
    "])\n",
    "\n",
    "# getting data pre processor object\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"Categorical_Pipeline\", onehot_encoder_pipeline, onhot_features), \n",
    "        (\"Binary_encoder_pipeline\", binary_encoder_pipeline, binary_features), \n",
    "        (\"Numeric_Pipeline\", RobustScaler (), numerical_feature)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit transform the train data\n",
    "\n",
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Encoding Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manually encoding \"Yes\" as 0 and \"No\" as 1\n",
    "y = np.where(y.values == 'Yes', 0,1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Dataset\n",
    "\n",
    "### Handling Imbalanced Dataset Handling Imbalanced Target Variable.\n",
    "\n",
    " • Synthetic Minority Oversampling Technique or SMOTE is another technique to oversample the minority class.Simply adding duplicate records of minority class often don't add any new information to the model\n",
    "\n",
    " • SMOTE is one of the famous oversampling techniques and is very effective in handling class imbalance. The idea is to combine SMOTE with some undersampling techniques (ENN, Tomek) to increase the effectiveness of handling the imbalanced class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling the minority class. The strategy can be changed as required. \n",
    "smt = SMOTETomek (random_state=42, sampling_strategy='minority', n_jobs=-1) \n",
    "\n",
    "# Fit the model to generate the data. \n",
    "X_res, y_res = smt.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "Here should understand the Various Classification models with default values from these models we can choose top 4 with Highest Accuracy score and proceed with HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which returns all evaluation metrics for classification model\n",
    "\n",
    "def evaluate_clf(true, predicted):\n",
    "    acc = accuracy_score(true, predicted) # Calculate Accuracy\n",
    "    f1 = f1_score(true, predicted) # Calculate F1-score\n",
    "    precision = precision_score(true, predicted) # Calculate Precision\n",
    "    recall = recall_score(true, predicted) # Calculate Recall\n",
    "    roc_auc = roc_auc_score(true, predicted) #Calculate Roc\n",
    "    return acc, f1 , precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models which are required for model selection\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(), \"XGBClassifier\": XGBClassifier(),\n",
    "    #\"CatBoosting Classifier\": CatBoostClassifier(verbose=False), \n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which can evaluate models and return a report in Dataframe\n",
    "\n",
    "def evaluate_models (x, y, models):\n",
    "    '''\n",
    "    This function takes in X and y and models dictionary as input\n",
    "    It splits the data into Train Test split\n",
    "    Iterates through the given model dictionary and evaluates the metrics \n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "    # separate dataset into train and test X_train, X_test, y_train, y_test\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "    models_list = []\n",
    "    accuracy_list = []\n",
    "    auc = []\n",
    "    \n",
    "    for i in range(len(list (models))):\n",
    "        model = list(models.values()) [i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred=model.predict(X_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        \n",
    "        # Training set performance\n",
    "        model_train_accuracy, model_train_f1, model_train_precision, \\\n",
    "        model_train_recall, model_train_rocauc_score = evaluate_clf(y_train,y_train_pred)\n",
    "        \n",
    "        # Test set performance\n",
    "        model_test_accuracy, model_test_f1, model_test_precision, \\\n",
    "        model_test_recall, model_test_rocauc_score = evaluate_clf(y_test,y_test_pred)\n",
    "\n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "\n",
    "        print('Model Performance for training Set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "        print('---------------------')\n",
    "\n",
    "        print('Model Performance for test Set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_test_accuracy))\n",
    "        accuracy_list.append(model_test_accuracy)\n",
    "        print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "        auc.append(model_test_rocauc_score)\n",
    "        print('='*35)\n",
    "        print('\\n')\n",
    "\n",
    "    report = pd.DataFrame(list(zip(models_list, accuracy_list)),\n",
    "                          columns=['Model Name', 'Accuracy']).sort_values(by=['Accuracy'],ascending=False)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base report of all models  with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_report = evaluate_models(X=X_res, y=y_res, models=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here we can use CatBoost Classifier, XGBClassifier for Hyper Parameter Tuning\n",
    "\n",
    "## Hyperopt: Distributed Hyperparameter Optimization\n",
    "    • Hyperopt is a powerful python library for hyperparameter optimization developed by Jarnes Bergstra. Hyperopt uses a form of Bayesian optimization for parameter tuning that allows you to get the best parameters for a given model.\n",
    "    • Grid Search is exhaustive in case of Resources usage.\n",
    "    • Random Search, is random, so could miss the most important values. However, there is a superior method available through the Hyperopt package\n",
    "\n",
    "## Search space is where Hyperopt really gives you a many of sampling options:\n",
    "    • for categorical parameters you have hp.choice\n",
    "    • for integers you get hp.randit, hp.quniform, hp.qloguniform and hp.qlognormal\n",
    "    • for floats we have hp.normal, hp.uniform, hp.lognormal and hp.loguniform\n",
    "    • It is the most extensive sampling functionality out there.\n",
    "\n",
    "You define your search space before you run optimization but you can create very complex parameter spaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for XGBoost Model\n",
    "\n",
    "This is a function to minimize that receives hyperparameters values as input from the search space and returns the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an objective function for hyperopt\n",
    "def XGB_objective(params):\n",
    "    model = XGBClassifier(**params, n_jobs=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res,test_size=0.2, random_state=42)\n",
    "    model = model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search phase\n",
    "\n",
    "search_phase = {'max_depth': hp.quniform(\"max_depth\", 3, 10, 1),\n",
    "                'gamma': hp.uniform('gamma',1,9),\n",
    "                'colsample_bytree': hp.uniform('colsample_bytree',0,5,1),\n",
    "                'min_child_weight': hp.quniform('min_child_weight',0,10,1),\n",
    "                'n_estimators': 180,\n",
    "                'seed': 0\n",
    "                }\n",
    "\n",
    "xgb_trials = Trials()\n",
    "\n",
    "#using Fmin function to get best xgb_objective\n",
    "\n",
    "best_xgb = fmin(\n",
    "    fn = XGB_objective,\n",
    "    space = search_phase,\n",
    "    algo = tpe.suggest,\n",
    "    trials=xgb_trials,\n",
    "    max_evals=10,\n",
    "    rstate=np.random.default_rng()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an objective function for hyperopt\n",
    "def CatBoost_objective(params):\n",
    "    model = CatBoostClassifier(**params, verbose=False, thread_count=-1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res,test_size=0.2, random_state=42)\n",
    "    model = model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search phase\n",
    "\n",
    "search_phase = {\n",
    "    'learning_rate': hp.uniform('learning_rate',0.001,1),\n",
    "    'depth': scope.int(hp.quniform('max_depth',2,10,1)),\n",
    "    'iterations': scope.int(hp.quniform('iterations',50,1000,50)),\n",
    "    'l2_leaf_reg': scope.int(hp.quniform('l2_leaf_reg',1,50,1))\n",
    "}\n",
    "\n",
    "cat_trials = Trials()\n",
    "\n",
    "#using Fmin function to get best xgb_objective\n",
    "\n",
    "best_cat = fmin(\n",
    "    fn = CatBoost_objective,\n",
    "    space = search_phase,\n",
    "    algo = tpe.suggest,\n",
    "    trials=cat_trials,\n",
    "    max_evals=10,\n",
    "    rstate=np.random.default_rng()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameters for CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(**params, verbose=False, thread_count=-1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res,test_size=0.2, random_state=42)\n",
    "\n",
    "model = model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "matrix = confusion_matrix(y_test,y_pred)\n",
    "cm = ConfusionMatrixDisplay(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
